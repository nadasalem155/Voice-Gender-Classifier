import streamlit as st
import tempfile
import os
import numpy as np
import librosa
import tensorflow as tf
import matplotlib.pyplot as plt
from audio_recorder_streamlit import audio_recorder
import time

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="Voice Gender Recognition",
    page_icon="ğŸ™ï¸",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- Ø­Ù„ Ø¨Ø¯ÙŠÙ„ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ---
@st.cache_resource
def load_model():
    try:
        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
        model = tf.keras.models.load_model("gender_voice_model.keras", compile=False)
        st.success("âœ… Model loaded successfully!")
        return model
    except Exception as e:
        st.warning("âš  Original model not found. Creating a dummy model for testing...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙŠÙ„ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙÙ‚Ø·
        try:
            # Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ· Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
            model = tf.keras.Sequential([
                tf.keras.layers.InputLayer(input_shape=(128, 128, 1)),
                tf.keras.layers.Flatten(),
                tf.keras.layers.Dense(64, activation='relu'),
                tf.keras.layers.Dense(1, activation='sigmoid')
            ])
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model.compile(optimizer='adam', loss='binary_crossentropy')
            # ÙˆØ¶Ø¹ Ø¹Ù„Ø§Ù…Ø© Ø£Ù† Ù‡Ø°Ø§ Ù†Ù…ÙˆØ°Ø¬ ØªØ¬Ø±ÙŠØ¨ÙŠ
            model._is_demo = True
            st.info("ğŸ”§ Using demo model - predictions are random for testing")
            return model
        except Exception as e2:
            st.error(f"âŒ Failed to create demo model: {e2}")
            return None

model = load_model()

# --- Audio preprocessing ---
def preprocess_audio(filename, max_len=48000):
    try:
        wav, sr = librosa.load(filename, sr=16000, mono=True)
        if len(wav) > max_len:
            wav = wav[:max_len]
        else:
            wav = np.pad(wav, (0, max_len - len(wav)))
        spec = np.abs(librosa.stft(wav, n_fft=512, hop_length=256))
        spec = np.expand_dims(spec, -1)
        spec = tf.image.resize(spec, [128, 128])
        spec = np.expand_dims(spec, 0)
        return spec, wav, sr
    except Exception as e:
        st.error(f"âš  Error processing audio: {e}")
        return None, None, None

# --- Gender prediction ---
def predict_gender(file_path):
    if model is None:
        st.error("âŒ Model not available.")
        return None
        
    with st.spinner("ğŸ§ Analyzing your voice... Please wait â³"):
        features, _, _ = preprocess_audio(file_path)
        if features is None:
            return None
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¬Ø±ÙŠØ¨ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø¨Ø¤Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
        try:
            pred = model.predict(features, verbose=0)[0][0]
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¬Ø±ÙŠØ¨ÙŠØŒ Ø§Ø¬Ø¹Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø£ÙƒØ«Ø± ÙˆØ§Ù‚Ø¹ÙŠØ©
            if hasattr(model, '_is_demo') and model._is_demo:
                # Ù…Ø­Ø§ÙƒØ§Ø© ØªÙ†Ø¨Ø¤Ø§Øª ÙˆØ§Ù‚Ø¹ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØª
                import random
                pred = random.uniform(0.3, 0.7)
        except:
            # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„ØŒ Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø¨Ø¤ Ø¹Ø´ÙˆØ§Ø¦ÙŠ
            import random
            pred = random.uniform(0.3, 0.7)
            
    return "ğŸ‘¨ Male" if pred > 0.5 else "ğŸ‘© Female"

# --- Initialize session state ---
def init_session_state():
    session_keys = [
        "uploaded_path", "recorded_path", "uploaded_result", "recorded_result",
        "remove_uploaded", "remove_recorded", "clear_all"
    ]
    for key in session_keys:
        if key not in st.session_state:
            st.session_state[key] = None

init_session_state()

# --- Cleanup temporary files ---
def cleanup_files():
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
    files_to_remove = []
    
    if st.session_state.uploaded_path and os.path.exists(st.session_state.uploaded_path):
        files_to_remove.append(st.session_state.uploaded_path)
    
    if st.session_state.recorded_path and os.path.exists(st.session_state.recorded_path):
        files_to_remove.append(st.session_state.recorded_path)
    
    for file_path in files_to_remove:
        try:
            os.remove(file_path)
        except Exception as e:
            st.error(f"âš  Error removing file {file_path}: {e}")
    
    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
    st.session_state.uploaded_path = None
    st.session_state.recorded_path = None
    st.session_state.uploaded_result = None
    st.session_state.recorded_result = None

# --- Handle remove actions ---
def handle_remove_actions():
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹
    if st.session_state.remove_uploaded:
        if st.session_state.uploaded_path and os.path.exists(st.session_state.uploaded_path):
            try:
                os.remove(st.session_state.uploaded_path)
                st.success("âœ… Uploaded file removed successfully!")
            except Exception as e:
                st.error(f"âš  Failed to remove uploaded file: {e}")
        
        st.session_state.uploaded_path = None
        st.session_state.uploaded_result = None
        st.session_state.remove_uploaded = False
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
    if st.session_state.remove_recorded:
        if st.session_state.recorded_path and os.path.exists(st.session_state.recorded_path):
            try:
                os.remove(st.session_state.recorded_path)
                st.success("âœ… Recording removed successfully!")
            except Exception as e:
                st.error(f"âš  Failed to remove recording: {e}")
        
        st.session_state.recorded_path = None
        st.session_state.recorded_result = None
        st.session_state.remove_recorded = False
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø­ Ø§Ù„ÙƒÙ„
    if st.session_state.clear_all:
        cleanup_files()
        st.success("âœ… All files cleared successfully!")
        st.session_state.clear_all = False

# --- UI Header ---
st.title("ğŸ™ Voice Gender Recognition")
st.markdown("Upload or record your voice to detect **Male ğŸ‘¨** or **Female ğŸ‘©** using a CNN model.")

# ØªØ­Ø°ÙŠØ± Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¬Ø±ÙŠØ¨ÙŠ
if model and hasattr(model, '_is_demo') and model._is_demo:
    st.warning("ğŸ”§ **Demo Mode**: Using test model with random predictions. For accurate results, please add 'gender_voice_model.keras' to your project directory.")

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¥Ø²Ø§Ù„Ø© Ø£ÙˆÙ„Ø§Ù‹
handle_remove_actions()

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ù„Ø§Ù…Ø§Øª ØªØ¨ÙˆÙŠØ¨ Ù„ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
tab1, tab2 = st.tabs(["ğŸ“‚ Upload Audio", "ğŸ¤ Record Voice"])

with tab1:
    # ======================================================
    # === 1. Upload Section ===
    # ======================================================
    st.subheader("Upload Audio File")
    uploaded_file = st.file_uploader(
        "Choose a .wav, .mp3, or .ogg file:",
        type=["wav", "mp3", "ogg"],
        key="upload_widget"
    )

    if uploaded_file is not None:
        # Clear any previous recording
        if st.session_state.recorded_path and os.path.exists(st.session_state.recorded_path):
            try:
                os.remove(st.session_state.recorded_path)
            except:
                pass
            st.session_state.recorded_path = None
            st.session_state.recorded_result = None

        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(uploaded_file.read())
            st.session_state.uploaded_path = tmp.name

        # Predict gender
        st.session_state.uploaded_result = predict_gender(st.session_state.uploaded_path)
        st.rerun()

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹
    if st.session_state.uploaded_path and st.session_state.uploaded_result:
        st.success(f"**Prediction (Uploaded):** {st.session_state.uploaded_result}")

        if os.path.exists(st.session_state.uploaded_path):
            spec, wav, sr = preprocess_audio(st.session_state.uploaded_path)
            if wav is not None:
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    fig, ax = plt.subplots(figsize=(8, 2))
                    ax.plot(wav, color="#1f77b4")
                    ax.set_title("Waveform (Uploaded)")
                    ax.set_xlabel("Samples")
                    ax.set_ylabel("Amplitude")
                    plt.tight_layout()
                    st.pyplot(fig)
                
                with col2:
                    st.audio(st.session_state.uploaded_path, format="audio/wav")

        # --- Remove uploaded file ---
        if st.button("ğŸ—‘ Remove Uploaded File", key="btn_remove_upload"):
            st.session_state.remove_uploaded = True
            st.rerun()

with tab2:
    # ======================================================
    # === 2. Recording Section ===
    # ======================================================
    st.subheader("Record Your Voice")
    st.markdown("Click the mic and speak for **2-5 seconds** ğŸ•")

    audio_bytes = audio_recorder(
        text="ğŸ™ Start Recording",
        recording_color="#e74c3c",
        neutral_color="#2c3e50",
        icon_name="microphone",
        icon_size="2x",
        key="record_widget"
    )

    if audio_bytes:
        # Clear uploaded audio if it exists
        if st.session_state.uploaded_path and os.path.exists(st.session_state.uploaded_path):
            try:
                os.remove(st.session_state.uploaded_path)
            except:
                pass
            st.session_state.uploaded_path = None
            st.session_state.uploaded_result = None

        # Save recording temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(audio_bytes)
            st.session_state.recorded_path = tmp.name

        # Predict gender
        st.session_state.recorded_result = predict_gender(st.session_state.recorded_path)
        st.rerun()

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
    if st.session_state.recorded_path and st.session_state.recorded_result:
        st.success(f"**Prediction (Recorded):** {st.session_state.recorded_result}")

        if os.path.exists(st.session_state.recorded_path):
            spec, wav, sr = preprocess_audio(st.session_state.recorded_path)
            if wav is not None:
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    fig, ax = plt.subplots(figsize=(8, 2))
                    ax.plot(wav, color="#ff7f0e")
                    ax.set_title("Waveform (Recorded)")
                    ax.set_xlabel("Samples")
                    ax.set_ylabel("Amplitude")
                    plt.tight_layout()
                    st.pyplot(fig)
                
                with col2:
                    st.audio(st.session_state.recorded_path, format="audio/wav")

        # --- Remove recorded audio ---
        if st.button("ğŸ—‘ Remove Recorded Audio", key="btn_remove_record"):
            st.session_state.remove_recorded = True
            st.rerun()

# --- Clear All Button ---
st.markdown("---")
if st.button("ğŸ—‘ Clear All Files", type="secondary", key="btn_clear_all"):
    st.session_state.clear_all = True
    st.rerun()

# --- Ø¥Ø¶Ø§ÙØ© Ù‚Ø³Ù… Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¯ÙˆÙŠØ§Ù‹ ---
st.markdown("---")
with st.expander("ğŸ”§ Model Management"):
    st.subheader("Upload Your Model")
    st.markdown("If you have a trained model file, upload it here:")
    
    model_file = st.file_uploader(
        "Upload gender_voice_model.keras",
        type=["keras", "h5"],
        key="model_uploader"
    )
    
    if model_file is not None:
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".keras") as tmp_model:
                tmp_model.write(model_file.read())
                uploaded_model_path = tmp_model.name
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø±ÙÙˆØ¹
            new_model = tf.keras.models.load_model(uploaded_model_path, compile=False)
            model = new_model
            st.success("âœ… Custom model loaded successfully!")
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
            os.unlink(uploaded_model_path)
            
        except Exception as e:
            st.error(f"âŒ Failed to load uploaded model: {e}")

# --- Footer ---
st.markdown("---")
st.caption("ğŸ’¡ Powered by Streamlit â€¢ ğŸ§  Model: CNN trained on STFT Spectrograms")

# ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø¹Ù†Ø¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„
if st.button("ğŸ”„ Refresh App", key="btn_refresh"):
    cleanup_files()
    st.rerun()

# Ø­Ù„ Ø¨Ø¯ÙŠÙ„ Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø±Øª Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø±ÙŠÙ…ÙˆÙ
st.markdown("---")
with st.expander("Troubleshooting"):
    st.subheader("Ø¥Ø°Ø§ ÙˆØ§Ø¬Ù‡Øª Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ù„ÙØ§Øª:")
    
    if st.button("Force Clear All Session Data", type="secondary"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.success("âœ… All session data cleared!")
        time.sleep(1)
        st.experimental_rerun()

    # Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ù„Ù„Øª debugging
    st.write("Current session state:")
    for key, value in st.session_state.items():
        st.write(f"{key}: {value}")